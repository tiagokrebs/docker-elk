## Local Elasticsearch Sample
# input {
# 	beats {
# 		port => 5044
# 	}
# 	tcp {
# 		port => 5000
# 	}
# }
## Add your filters / logstash plugins configuration here
# output {
# 	elasticsearch {
# 		hosts => "elasticsearch:9200"
# 		user => "logstash_internal"
# 		password => "${LOGSTASH_INTERNAL_PASSWORD}"
# 	}
# }

## Azure Sentinel Sample
input {
	# HTTP listener
	# See https://www.elastic.co/guide/en/logstash/current/plugins-inputs-http.html
	http {
		port => 8000
	}

	# TCP Listener, in case HTTP does not work
	# See https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html
	# tcp {
	# 	port => 5000
	# }
}
  
filter {
	# DTS payload is a NDJson so we need to split on the new line
	# See https://www.elastic.co/guide/en/logstash/current/plugins-filters-split.html

	# Split on new line method 1
	split {
		terminator => "\n"
	}

	# Split on new line method 2, in case the first does not work
# 	split { terminator => "
# " } 

	# Each line is a json so we need to parse
	# See https://www.elastic.co/guide/en/logstash/current/plugins-filters-json.html
	json {
		source => "message"
	}

}
  
output {
	# Sink method sugested on https://docs.microsoft.com/en-us/azure/sentinel/connect-logstash
	microsoft-logstash-output-azure-loganalytics {
		workspace_id => "<define me>" # <your workspace id>
		workspace_key => "<define me>" # <your workspace key>
		custom_log_table_name => "<define me>" # <your table>
	}
} 